---
title: "BBC_exp_tda"
author: "Matt O'Reilly"
date: "1/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(nonlinearTseries) #BuildTakens
library(TDAstats) #Calculate homology
library(tidyverse) 
library(dplyr)
library(readxl) #Read in data
library(tm) #NLP
library(superml) #Word count vectors
library(TDAmapper) #Mapper algorithm
```


###Word Freq Vectors
```{r}
text_data <- read_excel("./data/freq_vectors.xlsx")
#text_vector_data <- text_data %>% select(wordfreqvec)
text_data <- text_data[1:20,]
head(text_data)

```


```{r}
bettiNum_list <- list()
tfv <- TfIdfVectorizer$new(max_features = 100, remove_stopwords = TRUE)

for (i in 1:nrow(text_data)){
article <- removeNumbers(as.character(text_data['text'][i,])) #Remove numbers from articles
article_lines <- as.list(strsplit(article, "[.]")) #Split article into sentences
for (i in article_lines){
  cf_mat1 <- tfv$fit_transform(i)
}
hom <- calculate_homology(cf_mat1, return_df = TRUE)
bettinum <- sum((hom[, "death"] - hom[, "birth"] > 0.01) & hom[, "dimension"] == 1) 
bettiNum_list <- append(bettiNum_list, bettinum)
}

kmeans(bettiNum_list, 5, nstart = 5 ,iter.max = 15)


```
