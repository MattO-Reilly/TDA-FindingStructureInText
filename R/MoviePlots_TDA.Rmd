---
title: "MoviePlots_TDA"
author: "Matt O'Reilly"
date: "3/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Import libraries
library(plyr) #  for pre-processing 
library(tidyverse) # for pre-processing and visualisation
library(readxl)

#Natural Language Processing
library(superml)
library(tokenizers) #tokenize_sentences function
library(qdap)#rm_stopwords function
library(tm) #NLP
library(textstem) #Text Lemmatizer
library(superml)

#TDA
library(TDAmapper) #Mapper algorithm
library(igraph) #Plotting mapper
library(TDAstats)
library(TDA)
library(class)

#Multi-label KNN
library(mlr3)
```


```{r}
movies <- read_excel("../data/mpst_full_data.xlsx", col_types = 'text', .name_repair = "minimal")
movies <- movies [,1:6]

#Subset genres we will study
movies_single_genre <- movies[which(sapply(strsplit(movies$tags, " "), length) == 1),]
movies_romantic <- movies_single_genre[movies_single_genre$tags == 'romantic',]
movies_romantic <- movies_romantic[1:250,]
movies_entertainment <- movies_single_genre[movies_single_genre$tags == 'entertaining',]
movies_entertainment <- movies_entertainment[1:250,]
movies_comedy <- movies_single_genre[movies_single_genre$tags == 'comedy',]
movies_comedy <- movies_comedy[1:250,]
movies_murder <- movies_single_genre[movies_single_genre$tags == 'murder',]
movies_murder <- movies_murder[1:250,]


movies <- movies[1:800,]
movies<- movies[which(sapply(strsplit(movies$tags, " "), length) > 1),]
```

#Testing Conditions.
```{r}
subset <- grepl("romantic", movies$tags) | grepl("entertaining", movies$tags) | grepl("comedy", movies$tags) | grepl("murder", movies$tags)
#Subset Data so we have at least one of our chosen 4 categories to identify
movies<- movies[subset,]


movie_tags <- Corpus(VectorSource(movies$tags))

pattern = c("boring", "adult", "bleak", "cult", "flashback", "humor", "satire","paranormal","suspenseful", "good versus evil", "historical fiction", "psychedelic", "violence", "historical fiction", "allegory", "fantasy","horror", "gothic", "atmospheric", "inspiring", "queer", "stupid", "feel-good", "cruelty", "dramatic","action", "revenge", "sadist", "mystery", "neo noir", "tragedy", "haunting", "sentimental" , "historical", "storytelling", "home movie", "philosophical", "cute", "pornographic", "plot twist", "prank", "claustrophobic", "insanity", "brainwashing", "sci-fi", "dark", "psychological", "absurd", "alternate reality", "alternate history", "comic", "grindhouse film", "thought-provoking", "melodrama", "depressing", "realism", "western", "clever", "whimsical", "ent...", "intrigue", "realism", "anti war", "blaxploitation", "avant garde", "autobiographical", "suicidal", "magical")

corpus <- tm_map(movie_tags, removeWords, pattern)
movies$tags <- lapply(corpus, as.character)

#Remove duplicate tags
rem_dup_word <- function(x){
x <- tolower(x)
paste(unique(trimws(unlist(strsplit(x,split=" ",fixed=F,perl=T)))),collapse = 
" ")
}
movies$tags <- sapply(movies$tags, rem_dup_word)

movies$tags <- gsub("[.?!]*(?=[.?!]$)", "", movies$tags, perl=T)
movies$tags <- gsub(", ,","", movies$tags, perl=T)
movies$tags <- gsub(" ,","", movies$tags, perl=T)
movies$tags <- gsub(",","   ", movies$tags, perl=T)
movies$tags <- stripWhitespace(movies$tags)


movies$tags = unname(sapply(movies$tags, function(x) {
    paste(sort(trimws(strsplit(x, ','))), collapse=',')} ))
movies$tags <- gsub(" ",", ", movies$tags, perl=T)





##Create MultiLabels 
movies$romantic <- NA
movies$entertaining <- NA
movies$comedy <- NA
movies$murder <- NA

movies$romantic[str_detect(movies$tags, "romantic", negate = FALSE) == TRUE] <- 1
movies$romantic[is.na(movies$romantic)] <- 0

movies$entertaining[str_detect(movies$tags, "entertaining", negate = FALSE) == TRUE] <- 1
movies$entertaining[is.na(movies$entertaining)] <- 0

movies$comedy[str_detect(movies$tags, "comedy", negate = FALSE) == TRUE] <- 1
movies$comedy[is.na(movies$comedy)] <- 0

movies$murder[str_detect(movies$tags, "murder", negate = FALSE) == TRUE] <- 1
movies$murder[is.na(movies$murder)] <- 0
View(movies)

```


```{r}
clean_text <- function(x){ 
  gsub("…|⋆|–|‹|”|“|‘|’", " ", x) 
}

removeSingle <- function(x) gsub(" . ", " ", x)   

preprocess_corpus <- function(corpus){
  # Convert the text to lower case
  corpus <- tm_map(corpus, content_transformer(tolower))
  # Remove numbers
  corpus <- tm_map(corpus, removeNumbers)
  # Remove punctuations
  corpus <- tm_map(corpus, removePunctuation)
  # Remove special characters from text
  corpus <- tm_map(corpus, clean_text)
  # Remove english common stopwords
  corpus <- tm_map(corpus, removeWords, stopwords("english"))
  # Remove name of newspapers from the corpus
  corpus <- tm_map(corpus, removeWords, c("eagle rising","freedom daily"))
  # 'stem' words to root words
  corpus <- tm_map(corpus,stemDocument)
  # Eliminate extra white spaces
  corpus <- tm_map(corpus, stripWhitespace)
  #Remove single letter words
  corpus <- tm_map(corpus, content_transformer(removeSingle))
  terms <-TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = TRUE)))

  return (terms)
}

```

```{r, warning=FALSE}
barcode <- function(x) {
  category_tdm <- preprocess_corpus(Corpus(VectorSource(x)))
  category_tdm <- removeSparseTerms(category_tdm, 0.93)
  hom <- calculate_homology(category_tdm)
  plot_barcode(hom)
}
barcode(movies_comedy$plot_synopsis)
barcode(movies_entertainment$plot_synopsis)
barcode(movies_murder$plot_synopsis)
barcode(movies_romantic$plot_synopsis)
```

```{r warning=FALSE, include=FALSE}
bettinum <- function(x){
article <- as.character(x) 
article_lines <- unlist(strsplit(article, "(?<=[[:alnum:]]{3})[?!.]\\s", perl=TRUE)) #Split article into sentences
article_tdm <- preprocess_corpus(Corpus(VectorSource(article_lines)))
article_tdm <- removeSparseTerms(article_tdm, 0.95)
hom <- calculate_homology(article_tdm)
bettinum <- sum((hom[, "death"] - hom[, "birth"] >=0.0001) & hom[, "dimension"] == 1)
}
#movies$plot_synopsis[1:5]
bettiNum_list <- lapply(movies$plot_synopsis, bettinum)
movies$Betti_Num <- bettiNum_list
```


```{r}
library(mldr)
library(utiml)
library(randomForest)
set.seed(8)
mat.df <- as.data.frame(as.matrix(dist(movies$Betti_Num), stringsAsfactors = FALSE))
mat.df <- cbind(mat.df, movies[,7:10])

# Create two partitions (train and test) of toyml multi-label dataset
movies_mldr <- mldr_from_dataframe(mat.df, labelIndices = c(455:458), attributes, "movies")


# Create two partitions (train, test) of emotions dataset
partitions <- c(train = 0.6, test = 0.4)
ds <- create_holdout_partition(movies_mldr, partitions, method="iterative")

#MLKNN
model <- mlknn(movies_mldr, k = 4, s=1)
pred <- predict(model, movies_mldr)


# Predict
test <- predict(model, ds$test, cores=parallel::detectCores())
#test

# Evaluate the models
measures <- c("F1") 

result <- cbind(
  Test = multilabel_evaluate(ds$tes, test, measures)
)

print(round(result, 3))

```

#Jaccard Index
```{r}
library('clusteval')
cluster_similarity(movies$romantic, movies$entertaining, movies$comedy, movies$murder, similarity="jaccard", method="independence")

```

