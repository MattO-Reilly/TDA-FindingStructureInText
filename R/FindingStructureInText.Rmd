---
title: "Text_TDA"
author: "Matt O'Reilly"
date: "1/1/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Import libraries
library(plyr) #  for pre-processing 
library(tidyverse) # for pre-processing and visualisation
library(readxl)

#Natural Language Processing
library(superml)
library(tokenizers) #tokenize_sentences function
library(qdap)#rm_stopwords function
library(tm) #NLP
library(textstem) #Text Lemmatizer

library(TDAstats)
library(nonlinearTseries)
```

```{r}
num_articles = 100
text_data <- read_excel("../data/freq_vectors.xlsx", col_types = 'text', .name_repair = "minimal")
text_data <- text_data[1:num_articles,]
```

```{r}
text_data_tech <- text_data[text_data$category == 'tech', ]
text_data_tech

text_data_business <- text_data[text_data$category == 'business', ]
text_data_business

text_data_sport <- text_data[text_data$category == 'sport', ]
text_data_sport

text_data_entertainment <- text_data[text_data$category == 'entertainment', ]
text_data_entertainment

text_data_politics <- text_data[text_data$category == 'politics', ]
text_data_politics

```

```{r}
clean_text <- function(x){ 
  gsub("…|⋆|–|‹|”|“|‘|’", " ", x) 
}

preprocess_corpus <- function(corpus){
  # Convert the text to lower case
  corpus <- tm_map(corpus, content_transformer(tolower))
  # Remove numbers
  corpus <- tm_map(corpus, removeNumbers)
  # Remove punctuations
  corpus <- tm_map(corpus, removePunctuation)
  # Remove special characters from text
  corpus <- tm_map(corpus, clean_text)
  # Remove english common stopwords
  corpus <- tm_map(corpus, removeWords, stopwords("english"))
  # Remove name of newspapers from the corpus
  corpus <- tm_map(corpus, removeWords, c("eagle rising","freedom daily"))
  # 'stem' words to root words
  corpus <- tm_map(corpus,stemDocument)
  # Eliminate extra white spaces
  corpus <- tm_map(corpus, stripWhitespace)
  return (corpus)
}
```

```{r warning=FALSE}
article_tech <- preprocess_corpus(Corpus(VectorSource(text_data_tech$text)))
article_business <- preprocess_corpus(Corpus(VectorSource(text_data_business$text)))
article_sport <- preprocess_corpus(Corpus(VectorSource(text_data_sport$text)))
article_entertainment <- preprocess_corpus(Corpus(VectorSource(text_data_entertainment$text)))
article_politics <- preprocess_corpus(Corpus(VectorSource(text_data_politics$text)))
```

```{r}
tech_dtm <- TermDocumentMatrix(article_tech)
hom_tech <- calculate_homology(as.matrix(tech_dtm), return_df = FALSE)
plot_barcode(hom_tech)
tech_dtm <- removeSparseTerms(tech_dtm, 0.99)
tech_freqwords <- findMostFreqTerms(tech_dtm, n = 100)
```

```{r}
business_dtm <- TermDocumentMatrix(article_business)
business_tech <- calculate_homology(as.matrix(business_dtm), return_df = FALSE)
plot_barcode(business_tech)
business_dtm <- removeSparseTerms(business_dtm, 0.99)
business_freqwords <- findMostFreqTerms(business_dtm, n = 100)
```

```{r}
sport_dtm <- TermDocumentMatrix(article_sport)
sport_tech <- calculate_homology(as.matrix(sport_dtm), return_df = FALSE)
plot_barcode(sport_tech)
sport_dtm <- removeSparseTerms(sport_dtm, 0.99)
sport_freqwords <- findMostFreqTerms(sport_dtm, n = 100)
```

```{r}
entertainment_dtm <- TermDocumentMatrix(article_entertainment)
entertainment_tech <- calculate_homology(as.matrix(entertainment_dtm), return_df = FALSE)
plot_barcode(entertainment_tech)
entertainment_dtm <- removeSparseTerms(entertainment_dtm, 0.99)
entertainment_freqwords <- findMostFreqTerms(entertainment_dtm, n = 100)
```

```{r}
politics_dtm <- TermDocumentMatrix(article_politics)
politics_tech <- calculate_homology(as.matrix(politics_dtm), return_df = FALSE)
plot_barcode(politics_tech)
politics_dtm <- removeSparseTerms(politics_dtm, 0.99)
politics_freqwords <- findMostFreqTerms(politics_dtm, n = 100)
#findFreqTerms(review_dtm, 10)
```


```{r warning=FALSE}
tfv <- TfIdfVectorizer$new(max_features = 200, remove_stopwords = TRUE)

article <- preprocess_corpus(Corpus(VectorSource(text_data$text[1])))
review_dtm <- DocumentTermMatrix(article)

data <- as.matrix(inspect(review_dtm))
calculate_homology(data)
```

